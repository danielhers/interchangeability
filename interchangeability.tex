%
% File sib-rep.tex
%
\documentclass{article}
\PassOptionsToPackage{numbers}{natbib}

\usepackage{latexsym}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Interchangeability in Word Embedding Models}

\author{
Daniel Hershcovich \qquad Noam Slonim \\
IBM Research\\
\texttt{\{danielh,noams\}@il.ibm.com}
}

\begin{document}
    \maketitle

    \begin{abstract}
    We investigate the extent to which word embedding models
    preserve interchangeability, as reflected by distances between
    word vectors, and the effect of hyperparameters---context window size in particular.
    We use part-of-speech (POS) as a proxy for interchangeability,
    considering words to be interchangeable if they have the same POS.
    We also investigate the relationship between interchangeability
    and similarity as judged by commonly used word similarity benchmarks,
    and correlate the result with the performance of word embedding models
    on these benchmarks.
    \end{abstract}

    \section{Introduction}\label{sec:introduction}

    Word embedding models attempt to capture the semantic space of words
    in a metric space of real-valued vectors.
    While it is common knowledge that the hyperparameters used to train these
    models affects the semantic properties of the distances arising from them
    \cite{goldberg2016primer}, we are not aware of prior work quantifying the
    relation between specific semantic relations and model hyperparameters.
    In this work, we begin to answer this question.
    As a test case, experiment with the word2vec CBOW model
    \cite{mikolov2013efficient}, taking context window size as a hyperparameter,
    and look at interchangeability of words as a semantic relation.
    Although many semantic relations are captured by WordNet
    \cite{yang2006verb,agirre2009study},
    we interpret interchangeability for this work as having the same part-of-speech
    (POS).
    
    Word embedding models often start by extracting co-occurrences from a text
    corpus, and then perform learning on the extracted co-occurrence matrix
    (either by training a neural network to predict words based on their neighbors,
    as in word2vec, or by performing some manipulation,
    such as dimensionality reduction, to the co-occurrence matrix).
    Co-occurrences are often extracted by finding, for each word token, all
    words within a constant-size window around that word (or a randomly-sized
    window up to a certain maximal size, as in word2vec).
    The size of the window (or the maximal size)
    is a hyperparameter referred to as the \textit{context window size}.

    Our experiments reveal that context window size is negatively correlated
    with the presence of same-POS words in the 50 nearest neighbors of words
    according to an embedding model using that context window size.
    
    Our code is available\footnote{\url{https://github.ibm.com/DANIELH/sib}}.
    
    
    
    \section{Benchmarks}\label{sec:benchmarks}

    Many benchmarks have been proposed for the evaluation of unsupervised word
    representations.
    In general, they can be divided into intrinsic and extrinsic evaluation methods~\cite{schnabel2015evaluation,jastrzebski2017evaluate,alshargi2018concept2vec,bakarov2018survey,chiu2016intrinsic}.
    While most datasets measure the semantic similarity between words,
    many datasets actually capture semantic relatedness
    \cite{hill2015simlex,avraham2016improving},
    or more complex relations such as analogy or the ability to categorize
    words based on the distributed representation encoded in word embeddings.
    We evaluate on the following benchmarks:
    
    \paragraph{Similarity.}
    
    \begin{itemize}
        \item MTurk-287~\cite{radinsky2011word}
        \item MTurk-771~\cite{halawi2012large}
        \item WordSim-353~\cite{finkelstein2001placing}
        \item RG65~\cite{rubenstein1965contextual}
        \item Rare Word~\cite{luong2013better}
        \item SimLex999~\cite{hill2015simlex}
        \item WordSim-353-Sim~\cite{agirre2009study}
        \item SimVerb-3500~\cite{Gerz2016emnlp}
%        \item YP-130~\cite{yang2006verb}
%        \item MC-30~\cite{miller1991contextual}
    \end{itemize}
    
    \paragraph{Relatedness.}
    
    \begin{itemize}
        \item MEN~\cite{bruni2012distributional}
        \item WordSim-353-Rel~\cite{zesch2008using}
        \item TR9856~\cite{levy2015tr9856}
        \item WORT~\cite{eindor2018semantic}
    \end{itemize}
    
    \paragraph{Analogy.}
    
    \begin{itemize}
        \item MSR WordRep~\cite{gao2014wordrep}
        \item Google~\cite{mikolov2013distributed}
        \item SemEval 2012 task 2~\cite{jurgens2012semeval}
    \end{itemize}
    
    \paragraph{Categorization.}
    
    \begin{itemize}
        \item AP~\cite{almuhareb2005concept}
        \item BLESS~\cite{baroni2011we}
        \item Battig~\cite{battig1969category}
    \end{itemize}


    \bibliographystyle{plain}
    \bibliography{references}
%    \bibliographystyle{plainnat}
\end{document}
